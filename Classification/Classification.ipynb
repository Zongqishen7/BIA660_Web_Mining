{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Supervised Learning - Text Classification</center>\n",
    "References:\n",
    "* http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finally, we come to machine learning ...\n",
    "<img src='https://res.cloudinary.com/practicaldev/image/fetch/s--_jRAhLTB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/7brl707yigrhno91vc6d.jpg' width = \"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Review basic concepts of machine learning\n",
    "  * Cross validation\n",
    "  * Performance metrics: recall and precision, AUC, PRC\n",
    "* Text Classification  \n",
    "  * Assign a document into one  or more pre-defined categories (or labels)\n",
    "  * **Single-label**: e.g. spam dection, sentiment detection\n",
    "  * **Multi-label**: e.g. news categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review basic concepts of machine learning (see slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Problem formulation:\n",
    "    * Input: \n",
    "      - A document $d$ \n",
    "      - A fixed set of classes C = {$c_1$, $c_2$,..., $c_J$}\n",
    "      - A training set of $m$ hand-labeled documents ($d_1,c_1$),....,($d_m,c_m$)\n",
    "    * Output: a classifier that predicts $d$ to some classes $c$ $\\subset$ C\n",
    "* Basic process\n",
    "  1. Load and preprocess sample data\n",
    "  2. Extract features: e.g. bag of words with TF-IDF weights\n",
    "  3. Split feature space into trainning and test sets following cross validation method\n",
    "  4. Train a classifier/model with the training dataset using selected classification algorithm for each fold\n",
    "  5. Calculate performance\n",
    " \n",
    "* Considerations for deciding text classification algorithms\n",
    "  - should be effective in high dimensional spaces (`curse of dimensionality`)\n",
    "  - should be effective even if `the number of features is greater than the number of samples`\n",
    "  - some good algorithms to start with:\n",
    "      - Naive Bayes: baseline for performance benchmarking of text classification algorithms. \n",
    "      - Support Vector Machine (SVM). \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "                    \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: sd345@city.ac.uk (Michael Collier)\\nSubj...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: stanly@grok11.columbiasc.ncr.com (stanly...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   label\n",
       "0  From: sd345@city.ac.uk (Michael Collier)\\nSubj...           comp.graphics\n",
       "1  From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...           comp.graphics\n",
       "2  From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...  soc.religion.christian\n",
       "3  From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...  soc.religion.christian\n",
       "4  From: stanly@grok11.columbiasc.ncr.com (stanly...  soc.religion.christian"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.: Load data \n",
    "# Load datasets (http://qwone.com/~jason/20Newsgroups/)\n",
    "# For convenience, a subset of the data has been saved into \"twenty_news_data.csv\"\n",
    "\n",
    "data=pd.read_csv(\"twenty_news_data.csv\",header=0)\n",
    "data.head()\n",
    "\n",
    "# print out the full text of the first sample\n",
    "print(data[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. TF-IDF matrix generation\n",
    "- Function: **sklearn.feature_extraction.text.TfidfVectorizer**(input='content',encoding='utf-8', decode_error='strict', token_pattern='(?u)\\b\\w\\w+\\b', lowercase=True, stop_words=None, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, smooth_idf=True, ...)\n",
    "- Some useful parameters:\n",
    "    * **input** : string {'filename', 'file', 'content').\n",
    "    * **token_pattern** : Regular expression denoting what constitutes a “token”. The default is '(?u)\\b\\w\\w+\\b', i.e. a token contains at least two word characters in unicode (note: ?u: unicode, \\b: space or non-word character, i.e. boundary, \\w: word character). \n",
    "    * **ngram_range** : tuple (min_n, max_n): The lower and upper boundary of the range of n-values for different n-grams to be extracted. \n",
    "    * **stop_words** : string {‘english’}, list, or None (default)\n",
    "    * **lowercase** : boolean, default True: Convert all characters to lowercase before tokenizing.\n",
    "    * **max_df/min_df** : float in range [0.0, 1.0] or int, default=1.0: When building the vocabulary ignore terms that have a document frequency strictly higher (lower) than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "    * **max_features** : int or None, default=None. If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "    * **norm** : 'l1', 'l2' or None, optional. Norm used to normalize term vectors. None for no normalization.\n",
    "    * **use_idf** : boolean, default=True. Enable inverse-document-frequency reweighting.\n",
    "    * **smooth_idf** : boolean, default=True. Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.\n",
    "- For all the parameters, see http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2 Create TF-IDF Matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the TfidfVectorizer without any parameters\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "# with stop words removed\n",
    "#tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "# generate tfidf matrix\n",
    "dtm= tfidf_vect.fit_transform(data[\"text\"])\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words: 35788\n",
      "type of vocabulary: <class 'dict'>\n",
      "index of word 'city' in vocabulary: 8696\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3. Examine TF-IDF\n",
    "\n",
    "# 1. Check vocabulary\n",
    "\n",
    "# Vocabulary is a dictionary mapping a word to an index\n",
    "\n",
    "# the number of words in the vocabulary\n",
    "print(\"total number of words:\", len(tfidf_vect.vocabulary_))\n",
    "\n",
    "print(\"type of vocabulary:\", \\\n",
    "      type(tfidf_vect.vocabulary_))\n",
    "print(\"index of word 'city' in vocabulary:\", \\\n",
    "      tfidf_vect.vocabulary_['city'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text: \n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "\n",
      "tfidf weights: \n",
      "\n",
      "Vectorized document shape:  (35788,) \n",
      "\n",
      "top words:\n",
      "collier:\t0.384\n",
      "city:\t0.314\n",
      "071:\t0.256\n",
      "laserjet:\t0.246\n",
      "477:\t0.246\n",
      "converting:\t0.216\n",
      "michael:\t0.196\n",
      "iii:\t0.186\n",
      "hp:\t0.174\n",
      "files:\t0.136\n",
      "sd345:\t0.135\n",
      "8565:\t0.135\n",
      "ec1v:\t0.135\n",
      "x3769:\t0.135\n",
      "0hb:\t0.135\n",
      "tif:\t0.128\n",
      "email:\t0.126\n",
      "ac:\t0.125\n",
      "hpgl:\t0.123\n",
      "img:\t0.123\n"
     ]
    }
   ],
   "source": [
    "# 3.4 check words with top tf-idf wights in a document, \n",
    "# e.g. 1st document\n",
    "\n",
    "# get mapping from word index to word\n",
    "# i.e. reversal mapping of tfidf_vect.vocabulary_\n",
    "voc_lookup={tfidf_vect.vocabulary_[word]:word \\\n",
    "            for word in tfidf_vect.vocabulary_}\n",
    "\n",
    "print(\"\\nOriginal text: \\n\"+data[\"text\"][0])\n",
    "\n",
    "print(\"\\ntfidf weights: \\n\")\n",
    "\n",
    "# first, covert the sparse matrix row to a dense array\n",
    "doc0=dtm[0].toarray()[0]\n",
    "print(\"Vectorized document shape: \", doc0.shape, \"\\n\")\n",
    "\n",
    "# get index of top 20 words\n",
    "print(\"top words:\")\n",
    "top_words=(doc0.argsort())[::-1][0:20]\n",
    "for i in top_words:\n",
    "    print(\"{0}:\\t{1:.3f}\".format(voc_lookup[i], doc0[i]))\n",
    "#[(voc_lookup[i], '%.3f'%doc0[i]) for i in top_words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soc.religion.christian' 'sci.med' 'comp.graphics']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1604    soc.religion.christian\n",
       "1036                   sci.med\n",
       "2144             comp.graphics\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 3.5. classification using a single fold\n",
    "\n",
    "# use MultinomialNB algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import method for split train/test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import method to calculate metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, data[\"label\"], test_size=0.3, random_state=0)\n",
    "\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "#clf = MultinomialNB(alpha=0.5).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict the news group for the test dataset\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "# check a few samples\n",
    "print(predicted[0:3])\n",
    "y_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "precision:  [1.    0.97  0.97  0.781]\n",
      "recall:  [0.74  0.948 0.93  0.984]\n",
      "f-score:  [0.85  0.959 0.95  0.871]\n",
      "support:  [146 172 172 188]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       1.00      0.74      0.85       146\n",
      "         comp.graphics       0.97      0.95      0.96       172\n",
      "               sci.med       0.97      0.93      0.95       172\n",
      "soc.religion.christian       0.78      0.98      0.87       188\n",
      "\n",
      "              accuracy                           0.91       678\n",
      "             macro avg       0.93      0.90      0.91       678\n",
      "          weighted avg       0.92      0.91      0.91       678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.6. Performance evaluation: \n",
    "# precision, recall, f1-score\n",
    "\n",
    "# get the list of unique labels\n",
    "labels=sorted(data[\"label\"].unique())\n",
    "\n",
    "# calculate performance metrics. \n",
    "# Support is the number of occurrences of each label\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels)\n",
    "\n",
    "print(\"labels: \", labels)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"f-score: \", fscore)\n",
    "print(\"support: \", support)\n",
    "\n",
    "# another way to get all performance metrics\n",
    "print(classification_report\\\n",
    "      (y_test, predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.139, 0.232, 0.309, 0.32 ],\n",
       "       [0.095, 0.013, 0.641, 0.251],\n",
       "       [0.057, 0.681, 0.127, 0.135]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1604    soc.religion.christian\n",
       "1036                   sci.med\n",
       "2144             comp.graphics\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 98.56%\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.7.  AUC \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# We need to get probabilities as predictions\n",
    "predict_p=clf.predict_proba(X_test)\n",
    "\n",
    "# a probability is generated for each label\n",
    "labels\n",
    "predict_p[0:3]\n",
    "# Ground-truth\n",
    "y_test[0:3]\n",
    "\n",
    "# let's just look at one label \"soc.religion.christian\"\n",
    "# convert to binary\n",
    "binary_y = np.where(y_test==\"soc.religion.christian\",1,0)\n",
    "\n",
    "# this label corresponds to last column\n",
    "y_pred = predict_p[:,3]\n",
    "\n",
    "# compute fpr/tpr by different thresholds\n",
    "# positive class has label \"1\"\n",
    "fpr, tpr, thresholds = roc_curve(binary_y, y_pred, \\\n",
    "                                 pos_label=1)\n",
    "# calculate auc\n",
    "print(\"AUC: {:.2%}\".format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure();\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2);\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--');\n",
    "plt.xlim([0.0, 1.0]);\n",
    "plt.ylim([0.0, 1.05]);\n",
    "plt.xlabel('False Positive Rate');\n",
    "plt.ylabel('True Positive Rate');\n",
    "plt.title('AUC of Naive Bayes Model');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb624e7d590>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.05)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Recall')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision_Recall_Curve of Naive Bayes Model')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 96.74%\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.8.  precision_recall_curve\n",
    "\n",
    "# compute precision/recall by different thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(binary_y, \\\n",
    "                                y_pred, pos_label=1)\n",
    "\n",
    "plt.figure();\n",
    "plt.plot(recall, precision, color='darkorange', lw=2);\n",
    "plt.xlim([0.0, 1.0]);\n",
    "plt.ylim([0.0, 1.05]);\n",
    "plt.xlabel('Recall');\n",
    "plt.ylabel('Precision');\n",
    "plt.title('Precision_Recall_Curve of Naive Bayes Model');\n",
    "plt.show();\n",
    "\n",
    "# Calculate area under PRC curve (a.k.a average precision)\n",
    "# calculate auc\n",
    "print(\"Average Precision: {:.2%}\".format(auc(recall, precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new sample tf_idf size: (2, 35788)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['soc.religion.christian', 'comp.graphics'], dtype='<U22')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.171, 0.044, 0.053, 0.732],\n",
       "       [0.174, 0.367, 0.234, 0.224]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 3.9.  predict new documents\n",
    "\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "\n",
    "# generate tfidf for new documents\n",
    "# note we use \"transform\" not \"fit_transform\"\n",
    "# transform creates tfidf vectors based on the\n",
    "# vocabulary established by \"fit_transform\" in Exercise 3.2.\n",
    "# tfidf_vect has been fitted\n",
    "X_new_tfidf = tfidf_vect.transform(docs_new)\n",
    "\n",
    "print(\"new sample tf_idf size:\", X_new_tfidf.shape)\n",
    "\n",
    "# prediction\n",
    "clf.predict(X_new_tfidf)\n",
    "clf.predict_proba(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.10. Classification with stop words removed\n",
    "# Can removing stop words improves performance?\n",
    "# In Exercise 3.2, uncomment line 10 and comment line 7\n",
    "# Run Exercise 3.2, 3.5-3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[0.922 0.936 0.924 0.939 0.941]\n",
      "\n",
      "Test data set average recall:\n",
      "[0.883 0.908 0.888 0.916 0.922]\n",
      "\n",
      "Test data set average f1 score:\n",
      "[0.89  0.914 0.894 0.921 0.927]\n",
      "\n",
      "Training data average f1 score:\n",
      "[0.961 0.959 0.957 0.954 0.96 ]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.10. Run 5-fold cross validation\n",
    "# to show the generalizability of the model\n",
    "\n",
    "# import cross validation method\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \\\n",
    "           \"f1_macro\"]\n",
    "\n",
    "clf = MultinomialNB()\n",
    "#clf = MultinomialNB(alpha=0.5)\n",
    "\n",
    "cv = cross_validate(clf, dtm, data[\"label\"], \\\n",
    "                    scoring=metrics, cv=5, \\\n",
    "                    return_train_score=True)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average f1 score:\")\n",
    "print(cv['test_f1_macro'])\n",
    "\n",
    "# To see the performance of training data set use \n",
    "# cv['train_xx_macro']\n",
    "print(\"\\nTraining data average f1 score:\")\n",
    "print(cv['train_f1_macro'])\n",
    "\n",
    "# The metrics are quite stable across folds.\n",
    "# The performance gap between training and test sets is small\n",
    "# This indicates the model has good generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.11. Multinominal NB \n",
    "# with different smoothing parameter alpha\n",
    "# comment line 11 and uncomment 12 in Exercise 3.8\n",
    "# use different alpha value to see if it affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[0.97  0.974 0.964 0.967 0.979]\n",
      "\n",
      "Test data set average recall:\n",
      "[0.968 0.974 0.962 0.964 0.978]\n",
      "\n",
      "Test data set average fscore:\n",
      "[0.969 0.974 0.963 0.965 0.978]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.12. SVM model\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "# initiate an linear SVM model\n",
    "clf = svm.LinearSVC()\n",
    "#clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "cv = cross_validate(clf, dtm, data[\"label\"], \\\n",
    "                    scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n",
    "\n",
    "\n",
    "#Small data set-> naive biases \n",
    "#Large data set-> SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Parameter tuning using grid search\n",
    "* Each classification model has a few parameters\n",
    "  * e.g. \"stop_words\": \"english\" or None, min_df: [1,2,3, ...]\n",
    "  * e.g. MultinomialNB(alpha=1.0)\n",
    "  * e.g. LinearSVC(C=1.0, penalty=’l2’, loss=’squared_hinge’,...)\n",
    "* Instead of tweaking the parameters of the various components, it is possible to run an exhaustive search of the best parameters on a grid of possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3.1 Grid search\n",
    "\n",
    "# import pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# build a pipeline which does two steps all together:\n",
    "# (1) generate tfidf, and (2) train classifier\n",
    "# each step is named, i.e. \"tfidf\", \"clf\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                   ])\n",
    "\n",
    "# set the range of parameters to be tuned\n",
    "# each parameter is defined as \n",
    "# <step name>__<parameter name in step>\n",
    "# e.g. min_df is a parameter of TfidfVectorizer()\n",
    "# \"tfidf\" is the name for TfidfVectorizer()\n",
    "# therefore, 'tfidf__min_df' is the parameter in grid search\n",
    "\n",
    "parameters = {'tfidf__min_df':[1, 2,5,10],\n",
    "              'tfidf__stop_words':[None,\"english\"],\n",
    "              'clf__alpha': [0.5,1.0,2.0],\n",
    "}\n",
    "\n",
    "# the metric used to select the best parameters\n",
    "metric =  \"f1_macro\"\n",
    "\n",
    "# GridSearch also uses cross validation\n",
    "gs_clf = GridSearchCV\\\n",
    "(text_clf, param_grid=parameters, \\\n",
    " scoring=metric, cv=5)\n",
    "\n",
    "# due to data volume and large parameter combinations\n",
    "# it may take long time to search for optimal parameter combination\n",
    "# you can use a subset of data to test\n",
    "gs_clf = gs_clf.fit(data[\"text\"], data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha:\t0.5\n",
      "tfidf__min_df:\t2\n",
      "tfidf__stop_words:\tenglish\n",
      "best f1 score: 0.968\n"
     ]
    }
   ],
   "source": [
    "# gs_clf.best_params_ returns a dictionary \n",
    "# with parameter and its best value as an entry\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(\"{0}:\\t{1}\".format(param_name,\\\n",
    "                                 gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"best f1 score: {:.3f}\".format(gs_clf.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3.2 Grid search\n",
    "# Modify Exercise 3.3 and Exercise 3.8 \n",
    "# to use the best parameters found\n",
    "# re-create the Multinominal NB classifier\n",
    "\n",
    "# also, when setting min_df to 2, check the size of  \n",
    "# your tf-idf feature matrix. \n",
    "# How much of the dimension is reduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-label classification\n",
    "- So far we only cover single-label classification, i.e. assign one class to each sample\n",
    "- Multilabel classification emerges as a challenging problem, where classes are not mutually exclusive \n",
    "  * music categorization \n",
    "  * semantic classification of images\n",
    "  * tagging\n",
    "- **One-Vs-the-Rest** Strategy (a.k.a **one-vs-all**)\n",
    "  * fitting one classifier per class. For each classifier, the class is fitted against all the other classes.\n",
    "  * for $n$ classes (labels), $n$ classifier is needed\n",
    "  * Advantage: good interpretability - Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier\n",
    "  * Disadvantage: \n",
    "     * many classifiers are created if there is a large number of classes\n",
    "     * ignore the structure (or dependencies) of classes\n",
    "- **Class indication matrix** (or **one-hot encoding**): Encode categorical integer features using a one-hot aka one-of-K scheme. \n",
    "\n",
    "| Document    | Money       | Investment | Crime & Justice |\n",
    "| :-----------|:-----------:|:----------:|:--------------:|\n",
    "| 1           | 0           |      0     | 1              |\n",
    "| 2           | 1           |      1     | 0              |\n",
    "| 3           | 1           |      0     | 0              |\n",
    "| 4           | 0           |      1     | 1              |\n",
    "\n",
    "- **dataset**: Yahoo News Ranked Multilabel Learning dataset (http://research.yahoo.com)\n",
    "  - A subset is selected\n",
    "  - 4 classes, 6426 samples\n",
    "  \n",
    "- **Discussion**: can you apply Naive Bayes for multi-label classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glenn neely reveals specific trading strategies for today s difficult marketstime is tue aug am et neowave founder discusses the three phases of every market and the best trading techniques for each vocus august in his new audio interview elliott wave expert and neowave founder glenn neely advises on specific trading strategies to survive the current challenging market based on his years of trading and forecasting experience neely describes the three phases of all markets and he provides advice on the best trading strategy to employ in the current market phase the three market phases are bottoming topping accumulation distribution and trending up or down the current phase of market action is most likely distribution neely explains we ve rallied significantly off s low and since january the market has been forming a top what type of strategies should traders use during this distribution phase the focus should be selling into strength as the market prepares for a top over the next few months in this period overbought and oversold indicators work the best look for overbought signals to sell into those overbought conditions with stops above the market get out of your short positions when the market is oversold most important focus on protecting capital select trades carefully and avoid big risky bets what s next after the stock market tops probably before december we ll start the final and most treacherous phase of this bear market which started at s high neely adds keep in mind a trending phase can produce the biggest profit potential at the lowest risk over the shortest period click to hear glenn neely s minute interview trading strategies for today s difficult markets in the next interview of glenn neely s stock market predictions series glenn neely will introduce his revolutionary neely river technology neely river focuses on how to manage trades in an unpredictable market environment how to enter positions move stops and exit positions without requiring any market perspective or forecasting expertise about glenn neely and neowave institute glenn neely who is internationally regarded as the premier elliott wave analyst founded the elliott wave institute in in neely published his advanced wave analysis process in his now classic book mastering elliott wave in neely changed the name of his research and advisory firm to neowave institute to differentiate his scientific wave analysis technology from orthodox subjective elliott wave analysis which is frequently nebulous inaccurate and constantly fluid what is elliott wave in the early ralph nelson elliott presented his theory of market behavior which quantifies each stage of an economic cycle into specific patterns of mass psychology glenn neely has devoted more than years to mastering and advancing the concepts of wave theory neely refined elliott wave theory to make it objective practical and consistently accurate producing his now famous neowave technology this precise step by step assessment of market structure leads to low risk high profit investing and trading orthodox elliott wave devoid of such technology and rules typically leaves the analyst with ambiguous interpretations seriously flawed results and dual directional forecasts today decades after r n elliott penned his original theory countless investors and traders trust neely s revolutionary step by step neowave approach to market analysis devotees of neowave institute and glenn neely are reaping the rewards of low risk high profit investing learn more about glenn neely and neowave institute at neowave institute inc patrice rhoades baum e mail information\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['money', 'investment-&-company-information', 'investment']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4.1 Multi-label classification- Load data\n",
    "\n",
    "import json\n",
    "data=json.load(open(\"ydata.json\",\"r\"))\n",
    "\n",
    "docs,labels=zip(*data)\n",
    "\n",
    "# show sample examples\n",
    "docs[1]\n",
    "labels[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6426, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['crime-&-justice', 'investment',\n",
       "       'investment-&-company-information', 'money'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2515, 3607, 3468, 3202])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4.2 One-hot coding of classes\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(labels)\n",
    "# check size of indicator matrix\n",
    "# print some rows \n",
    "Y[0:5]\n",
    "Y.shape\n",
    "# check classes\n",
    "mlb.classes_\n",
    "\n",
    "# check # of samples in each class\n",
    "np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 OneVsRestClassifier(estimator=LinearSVC(C=1.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         dual=True,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         intercept_scaling=1,\n",
       "                                                         loss='squared_hinge',\n",
       "                                                         max_iter=1000,\n",
       "                                                         multi_class='ovr',\n",
       "                                                         penalty='l2',\n",
       "                                                         random_state=None,\n",
       "                                                         tol=0.0001,\n",
       "                                                         verbose=0),\n",
       "                                     n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Exercise 4.3 Multi-label classification- one vs. rest classifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "                docs, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=\"english\",\\\n",
    "                              min_df=2)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1],\n",
       "       [0, 1, 1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                 crime-&-justice       0.98      0.98      0.98       764\n",
      "                      investment       0.91      0.97      0.94      1077\n",
      "investment-&-company-information       0.93      0.97      0.95      1032\n",
      "                           money       0.85      0.95      0.90       946\n",
      "\n",
      "                       micro avg       0.91      0.97      0.94      3819\n",
      "                       macro avg       0.92      0.97      0.94      3819\n",
      "                    weighted avg       0.92      0.97      0.94      3819\n",
      "                     samples avg       0.93      0.97      0.94      3819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4.4 Multi-label classification- Performance report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "predicted.shape\n",
    "print(\"predicted:\")\n",
    "predicted[0:2]\n",
    "print(\"actual:\")\n",
    "Y_test[0:2]\n",
    "\n",
    "print(classification_report\\\n",
    "      (Y_test, predicted, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
