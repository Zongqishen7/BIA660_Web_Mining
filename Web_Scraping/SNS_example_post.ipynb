{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>An example of SNS</center>\n",
    "\n",
    "- Threadless.com is a crowdsouring website for graphic designs.\n",
    "- Desginers submit artworks and recieve ratings from the community within a seven-day period. \n",
    "- Designs with the best scores will be selected to print on T-shirts and other products for sale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping objectives\n",
    "\n",
    "- Get a sample of users and artifacts. Consider a sampling strategy. \n",
    "- Scrape artifact-level features.\n",
    "- Scrape user-level features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.threadless.com/designs/archive?page=1', 'https://www.threadless.com/designs/archive?page=2', 'https://www.threadless.com/designs/archive?page=3', 'https://www.threadless.com/designs/archive?page=4', 'https://www.threadless.com/designs/archive?page=5']\n"
     ]
    }
   ],
   "source": [
    "# Get ten urls of pages as a sample of latest artifacts.\n",
    "\n",
    "link=\"https://www.threadless.com/designs/archive?page=\"\n",
    "num=list(range(1,6))\n",
    "pages=[]\n",
    "for i in num:\n",
    "    page=link+str(i)\n",
    "    pages.append(page)\n",
    "print(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on page https://www.threadless.com/designs/archive?page=1\n",
      "working on page https://www.threadless.com/designs/archive?page=2\n",
      "working on page https://www.threadless.com/designs/archive?page=3\n",
      "working on page https://www.threadless.com/designs/archive?page=4\n",
      "working on page https://www.threadless.com/designs/archive?page=5\n"
     ]
    }
   ],
   "source": [
    "# Get urls of all the designs in these ten pages\n",
    "# To reduce the load to their server, will demonnstrate one page\n",
    "\n",
    "designs=[]\n",
    "for i in pages:\n",
    "    print('working on page'+str(' ')+str(i))\n",
    "    response=requests.get(i)\n",
    "    soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "    links=soup.find('ol',class_='feed-archive th-grided')\n",
    "    li=links.find_all('li',class_=\"old\")\n",
    "    for j in li:\n",
    "        name=j.find(\"a\")[\"href\"]\n",
    "        designs.append(name)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/designs/wild-west-mandala-tee',\n",
       " '/designs/debra',\n",
       " '/designs/love-for-all-retro-style-lgbt-flag-gay-pride-month',\n",
       " '/designs/dinkygoose-mermaid',\n",
       " '/designs/pastel-goth-mermaid']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designs[:5]\n",
    "\n",
    "# can write out the sample of artifacts \n",
    "# with open('designs.csv', 'w') as csvfile:\n",
    "#    writer=csv.writer(csvfile, delimiter=',')\n",
    "#    writer.writerows(zip(designs))\n",
    "\n",
    "\n",
    "# read in your sample\n",
    "# raw_data_file = open(\"designs.csv\", 'r')\n",
    "# csv_data_file = csv.reader(raw_data_file, delimiter=',')\n",
    "# designs = []\n",
    "# for line in csv_data_file:\n",
    "#     print(line[0])\n",
    "#     designs.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Wild West Mandala Tee', 'alphabetempire', '2.60', '5')\n",
      "('Debra', 'muhaonline', '2.86', '35')\n",
      "('Love For All - RETRO Style LGBT Flag GAY PRIDE Month Transgender Rainbow Lesbian', 'makersyart', '3.63', '8')\n",
      "('dinkygoose - Mermaid', 'RedAppleTees', '2.74', '42')\n",
      "('Pastel Goth Mermaid', 'RedAppleTees', '3.18', '82')\n",
      "('Octo Mermaid', 'RedAppleTees', '3.51', '118')\n",
      "('Sincerely, What?', 'EliseTowleSnow', '1.46', '13')\n",
      "('Cute Demon Mermaid', 'RedAppleTees', '2.91', '54')\n",
      "('Summoning Circle - Chubby Goat Monster', 'RedAppleTees', '3.21', '73')\n",
      "('dinkygoose - Dark/Villain', 'RedAppleTees', '2.90', '48')\n",
      "('dinkygoose - Dark/Villain', 'RedAppleTees', '1.14', '7')\n",
      "('dinkygoose - Fall', 'RedAppleTees', '2.78', '40')\n",
      "('Halloween Kitties', 'RedAppleTees', '3.83', '134')\n",
      "('dinkygoose - Summer Time Fun', 'RedAppleTees', '3.16', '76')\n",
      "('Magical Kitty', 'RedAppleTees', '3.54', '110')\n",
      "('Chibi Angel Harpy', 'RedAppleTees', '2.58', '40')\n",
      "('Cthulhu', 'RedAppleTees', '2.59', '34')\n",
      "('LAST TIME!', 'sillyindustries', '2.57', '7')\n",
      "('Dinky Horde', 'RedAppleTees', '3.26', '76')\n",
      "('Pirate Mandala Tee', 'alphabetempire', '2.50', '4')\n",
      "('kawaii', 'mhs23', '2.93', '44')\n",
      "('Love you to death', 'DW18', '2.45', '22')\n",
      "('WEB!', 'sillyindustries', '2.67', '6')\n",
      "('Pastel purple snail on grass', 'Cqmw', '2.05', '20')\n",
      "('Octo-Push', 'rizalsalam', '2.40', '5')\n",
      "('Cat under a tree', 'Witcher1996', '1.62', '13')\n",
      "('Tech rooster', 'Tykennedy', '1.90', '20')\n",
      "('ADORABLE KITTEN', 'LarD8', '1.38', '13')\n",
      "('PDM Construction Help Wanted Handbill', 'dantastic773', '1.25', '4')\n",
      "('kawaii cube flamingo', 'deleaf', '1.33', '12')\n",
      "([], [], [], [])\n",
      "('Mothership', 'Bezzikapa', '3.75', '4')\n",
      "('Wait for my darling', 'Teefun', '1.50', '12')\n",
      "('Raccoon FUN ', 'StrawberryHead', '2.52', '29')\n",
      "('Kong cat', 'Bayuktx', '1.59', '17')\n",
      "('Raccoon Rainbow FUN', 'StrawberryHead', '2.06', '18')\n",
      "('Rainy Days', 'badbasilisk', '3.83', '6')\n",
      "('Unicorn Skull', 'JonzShop', '2.80', '5')\n",
      "('Just smile', 'Ghost27', '2.00', '7')\n",
      "('Adorable Killer - Chibi kawaii frankie', 'FreelancerMiel', '2.74', '47')\n",
      "('Adorable Killer - Chibi kawaii swamp monster', 'FreelancerMiel', '2.56', '36')\n",
      "('Adorable Killer - Chibi kawaii skeleton', 'FreelancerMiel', '2.51', '39')\n",
      "('Kawaii balloon lumpfishies', 'Lalah3', '2.27', '22')\n",
      "('Transgender Heart', 'Sploot_RI', '3.30', '10')\n",
      "('Cute Corgi', 'CatcoInk', '1.43', '14')\n",
      "('Monster', 'Ghost27', '3.50', '12')\n",
      "('A Bear in an Iceberg - The Icebearg', 'pawkybear', '2.33', '3')\n",
      "('This is a cat. I drew it myself.', 'dantastic773', '2.60', '5')\n",
      "('GIRL POWER', 'art-shirt73', '1.56', '18')\n",
      "('Kawaii Cat', 'Geo95m12', '2.28', '32')\n"
     ]
    }
   ],
   "source": [
    "# Get artifact level features\n",
    "# For each design, get title, author, average score, number of scores, challenge name\n",
    "\n",
    "rows=[]\n",
    "\n",
    "for i in designs[:50]:\n",
    "    try:\n",
    "        url=\"https://www.threadless.com\"+i\n",
    "        response=requests.get(url)\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # initiate the variable for each period\n",
    "        title=None\n",
    "        author=None\n",
    "        avg_score=None\n",
    "        total_score=None\n",
    "        \n",
    "        ##title\n",
    "        title=soup.select('div.submission-title h1')\n",
    "        if title!=[]:\n",
    "            title=title[0].text\n",
    "\n",
    "        ##author\n",
    "        author=soup.select('div.author-block a.author')\n",
    "        if author!=[]:\n",
    "            author=author[0].text\n",
    "\n",
    "        ##score\n",
    "        avg_score=soup.select('li.avg-score strong')\n",
    "        if avg_score!=[]:\n",
    "            avg_score=avg_score[0].text\n",
    "\n",
    "        ##total scores\n",
    "        total_score=soup.select('li.total-scores strong')\n",
    "        if total_score!=[]:\n",
    "            total_score=total_score[0].text\n",
    "        \n",
    "        rows.append((title, author, avg_score, total_score))\n",
    "        print((title, author, avg_score, total_score))\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threadless\n",
      " 115107 designs\n",
      "\n",
      "Kawaii Presented by Hot Topic\n",
      " 680 designs\n",
      "\n",
      "Pride Forever\n",
      " 933 designs\n",
      "\n",
      "Kawaii Presented by Hot Topic\n",
      " 680 designs\n",
      "\n",
      "Kawaii Presented by Hot Topic\n",
      " 680 designs\n"
     ]
    }
   ],
   "source": [
    "# Question: How to scrape the challenge information?\n",
    "\n",
    "# 1. challenge name\n",
    "# 2. how many designs per challenge\n",
    "\n",
    "\n",
    "# add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StrawberryHead', 'makersyart', 'dantastic773', 'RedAppleTees', 'mhs23', 'muhaonline', 'alphabetempire', 'Sploot_RI', 'FreelancerMiel', 'Geo95m12', 'deleaf', 'pawkybear', 'EliseTowleSnow', 'sillyindustries', 'badbasilisk', 'Bezzikapa', 'Lalah3', 'Ghost27', 'Cqmw', 'Bayuktx', 'art-shirt73', 'LarD8', 'CatcoInk', 'DW18', 'Tykennedy', 'rizalsalam', 'Witcher1996', 'JonzShop', 'Teefun']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get authors\n",
    "authors=[row[1] for row in rows]\n",
    "authors=filter(None, authors)\n",
    "authors_unique=list(set(authors))\n",
    "print(authors_unique)\n",
    "len(authors_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, '4 designs submitted', '30 designs scored', 'Avg Score Given: 1.97', 'Member since 2022', 'StrawberryHead']\n",
      "[None, '4 designs submitted', '5 designs scored', 'Avg Score Given: 4.60', 'Member since 2022', 'makersyart']\n",
      "[None, '152 designs submitted', '386 designs scored', 'Avg Score Given: 3.23', 'Member since 2013', 'dantastic773']\n",
      "[None, '49 designs submitted', '152 designs scored', 'Avg Score Given: 3.11', 'Member since 2018', 'RedAppleTees']\n",
      "[None, '3 designs submitted', None, 'Avg Score Given: 0.00', 'Member since 2021', 'mhs23']\n"
     ]
    }
   ],
   "source": [
    "# For the designers we found, get the summary of their experience\n",
    "full=[]\n",
    "\n",
    "for i in authors_unique[:5]:\n",
    "    url=\"https://www.threadless.com/@\"+i\n",
    "    time.sleep(5)\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # find all stats\n",
    "    stats=soup.select('div.stats ul')\n",
    "    li=stats[0].find_all('li')\n",
    "    \n",
    "    line=[None] * 5\n",
    "    for j in li:\n",
    "        char=(j.text).strip()\n",
    "        \n",
    "        # threads\n",
    "        if re.search(\"started\",char):\n",
    "            line[0]=char\n",
    "            #line[1]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "            \n",
    "        # submitted\n",
    "        if re.search(\"submitted\",char):\n",
    "            line[1]=char   \n",
    "            #line[1]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "\n",
    "        # scored\n",
    "        if re.search(\"scored\",char):\n",
    "            line[2]=char\n",
    "            #line[2]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "        \n",
    "        # given\n",
    "        if re.search(\"Given\",char):\n",
    "            line[3]=char\n",
    "            #line[3]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "\n",
    "        # since\n",
    "        if re.search(\"since\",char):\n",
    "            line[4]=char\n",
    "            #line[4]=re.findall(r\"[0-9.]+\", char)[0]\n",
    "    \n",
    "    line.append(i)\n",
    "    print(line)\n",
    "    full.append(line)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrawberryHead 2 6\n",
      "makersyart 0 37\n",
      "dantastic773 97 28\n",
      "RedAppleTees 1 284\n",
      "mhs23 0 12\n"
     ]
    }
   ],
   "source": [
    "# Question: how to scrape each designers' numbers of followers and following?\n",
    "\n",
    "\n",
    "\n",
    "# add you code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the follower-followee network for each designer.\n",
    "# Can we do this with beautifulsoup? \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bezzikapa', 'RedAppleTees']\n",
      "['Cqmw', 'mhs23']\n"
     ]
    }
   ],
   "source": [
    "relations=[]\n",
    "\n",
    "for i in authors_unique[3:5]:\n",
    "    \n",
    "    i=i.replace(\" \",\"%20\")\n",
    "    \n",
    "    follower_url=\"https://www.threadless.com/@\"+i+\"/followers\"\n",
    "    following_url=\"https://www.threadless.com/@\"+i+\"/following\"\n",
    "\n",
    "    # close a pop ad\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=gene\")\n",
    "    driver = webdriver.Chrome(options=opts)\n",
    "\n",
    "    # one's follower   \n",
    "    driver.get(follower_url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # you can scroll many times if not reaching the end\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  \n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html.encode('utf-8'),\"html.parser\")\n",
    "    comp=soup.find('ol',class_=\"following-list\")\n",
    "    comp=comp.find_all(\"li\")\n",
    "\n",
    "    line=[]\n",
    "    for k in comp:\n",
    "        name=k.find(\"a\")[\"href\"]\n",
    "        name=name.lstrip(\"/@\")\n",
    "        if name in authors_unique:\n",
    "            # one's followers send the following tie\n",
    "            line=[name, i]\n",
    "            print(line)\n",
    "            relations.append(line)\n",
    "    \n",
    "    # one's follwing\n",
    "    driver.get(following_url)\n",
    "    time.sleep(10)   \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")                \n",
    "    time.sleep(25)  \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html.encode('utf-8'),\"html.parser\")\n",
    "    comp=soup.find('ol',class_=\"following-list\")\n",
    "    comp=comp.find_all(\"li\")\n",
    "\n",
    "    line=[]\n",
    "    for k in comp:\n",
    "        name=k.find(\"a\")[\"href\"]\n",
    "        name=name.lstrip(\"/@\")\n",
    "        if name in authors_unique:\n",
    "            # one sends the following tie to those to follow\n",
    "            line=[i, name]\n",
    "            print(line)\n",
    "            relations.append(line)\n",
    "    driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
